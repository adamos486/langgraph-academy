{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T05:40:17.967288Z",
     "start_time": "2025-02-24T05:40:16.606560Z"
    }
   },
   "source": "!pip install --quiet -U langgraph langchain_ollama langchain_core",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fdae2b9aac153325"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**States** are the first things defined about the graph. These consist of the schema of the graph, and reducer functions to specify how to apply state updates.",
   "id": "645cfb853fd1fa54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:41:27.381893Z",
     "start_time": "2025-02-24T04:41:27.378923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ],
   "id": "1646c2199ff51579",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Nodes** are python functions (synchronous or asynchronous). The first positional argument is the state.",
   "id": "cb5e0e292bb4a10c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:41:31.647249Z",
     "start_time": "2025-02-24T04:41:31.642911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph state\": state['graph_state'] + \" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph state\": state['graph_state'] + \" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph state\": state['graph_state'] + \" sad!\"}"
   ],
   "id": "aea54b8711249557",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Schemas** are typically constructed in `TypedDict` types. `Pydantic` base models can also be used.",
   "id": "d6f2984444229647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:41:34.564460Z",
     "start_time": "2025-02-24T04:41:34.505266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "def answer_node(state: InputState):\n",
    "    return {\"answer\": \"bye\", \"question\": state[\"question\"]}\n",
    "\n",
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "builder.add_node(answer_node)\n",
    "builder.add_edge(START, \"answer_node\")\n",
    "builder.add_edge(\"answer_node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "print(graph.invoke({\"question\": \"hi\"}))"
   ],
   "id": "b9d65f4f6257d9ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'bye'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Edges** connect each node. Normal edges are used if you want to always go from like `node_1` to `node_2`.\n",
    "**Conditional edges** are used if you want optional routes between various nodes.\n",
    " ```python\n",
    "graph.add_conditional_edges(\"node_1\", routing_function)\n",
    "```\n",
    "The Routing function accepts current states of the graph, and returns a value. The default return value is used as the name of node or list of nodes to send the state to the next. Similar to functional programming chains.\n",
    "\n",
    "You can also provide a dictionary of optional routes.\n",
    "```python\n",
    "graph.add_conditional_edges(\"node_a\", routing_function, {True: \"node_b\", False: \"node_c\"})\n",
    "```"
   ],
   "id": "ab002f988df73645"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:41:38.534206Z",
     "start_time": "2025-02-24T04:41:38.530681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    user_input = state['graph_state']\n",
    "    if random.random() < 0.5:\n",
    "        return \"node_2\"\n",
    "    return \"node_3\""
   ],
   "id": "44dd4d0aa6daefe2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Once components have been defined above, they can be added to a graph. Start with a **StateGraph** class.\n",
    "\n",
    "The **StateGraph** class is the main graph class at this point. It's parameterized by a user defined `State` object.\n",
    "\n",
    "Initialize a StateGraph with `State` class as defined above:\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    graph_state: str\n",
    "```\n",
    "\n",
    "We use START nodes, that sends user input to the graph, to indicate where to start on the graph.\n",
    "The **START** node is a special node that represents the node that sends user input ot the graph, and the main purpose for referencing this node is to determine which nodes should be called first.\n",
    "\n",
    "```python\n",
    "from langgraph.graph import START\n",
    "graph.add_edge(START, \"node_a\")\n",
    "```\n",
    "The `END` node is a special node that represents a terminal node, and is referenced when you want to denote which edges have no actions after they are complete.\n",
    "\n",
    "```python\n",
    "from langgraph.graph import END\n",
    "\n",
    "graph.add_edge(\"node_a\", END)\n",
    "```"
   ],
   "id": "ae49506af690a115"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T04:41:42.131177Z",
     "start_time": "2025-02-24T04:41:41.295886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "2f22e999461d90b5",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:11:31.716079Z",
     "start_time": "2025-02-24T05:11:31.703713Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({\"graph_state\": \"Hi, this is Adam.\"})",
   "id": "fab98ec03c82e7f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is Adam.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:19:39.282083Z",
     "start_time": "2025-02-24T05:19:39.270216Z"
    }
   },
   "cell_type": "code",
   "source": "result = await graph.ainvoke({\"graph_state\": \"Hello there!\"})",
   "id": "822973324df8e698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tools\n",
    "**Tools** are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models. Tools are needed whenever you want a model to control parts of your code or call out to external APIs.\n",
    "\n",
    "A **tool** consists of:\n",
    "1. The `name` of the tool.\n",
    "2. A `description` of what the tool does.\n",
    "3. A `JSON schema` defining the inputs of the tool.\n",
    "4. A `function` (and, optionally, an async variant of the function).\n",
    "\n",
    "When a **tool** is bound to a model, the name, description, and JSON schema are provided as context to the model.\n",
    "\n",
    "Given a list of tools and a set of instructions, a model can request to call one ore more tools with specific inputs.\n",
    "\n",
    "```python\n",
    "tools = [...]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "ai_msg = llm_with_tools.invoke(\"do xyz...\")\n",
    "```\n",
    "\n",
    "The `AIMessage` returned from the model **MAY** have `tool_calls` associated with it.\n",
    "\n",
    "Tool calling allows a chat model to respond to a given prompt by generating output that matches a user-defined schema.\n",
    "\n",
    "```python\n",
    "AIMessage(\n",
    "    tool_calls=[{\n",
    "        name: \"get_weather\",\n",
    "        args: {\n",
    "            location: \"Hawaii\",\n",
    "        },\n",
    "    }]\n",
    ")\n",
    "```"
   ],
   "id": "85084d983dd9cb3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "HumanMessage, AIMessage, SystemMessage, and ToolMessage.\n",
    "\n",
    "Let's run through each type of message."
   ],
   "id": "b5977b820c2913fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:44:28.380347Z",
     "start_time": "2025-02-24T05:44:28.373988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\", name=\"Adam\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Adam\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ],
   "id": "51d4752f73164386",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Adam\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: Adam\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:46:09.545864Z",
     "start_time": "2025-02-24T05:45:45.090887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:7b\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)\n",
    "\n",
    "result"
   ],
   "id": "cad6eeea0b439b8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so the user asked for information on the best places to see Orcas in the US. I already told them they were researching ocean mammals and then asked which aspect they wanted info on. Now, they\\'ve specified focusing on Orcas.\\n\\nI need to provide a list of top locations with some details about each. The previous response included Alaska\\'s Haida Gorda Peninsula as the top spot because it has multiple Orcas sightings. So maybe I should start there and include other states like Washington for Orcas in WA and Idaho for Northern Orcas.\\n\\nI should explain why these places are good—maybe mention the number of sightings, how local regulations make the experience better. Also, tips like timing their visit during peak seasons or making reservations would be helpful.\\n\\nI should also highlight some specific attractions related to seeing Orcas, like boat tours, viewing areas, and nearby wildlife. Maybe add a tip about not overdoing it with Orcas to respect them while still enjoying the trip.\\n\\nI need to make sure each location is clearly described so the user knows what makes that spot special. Also, maybe include some tips on what else to do during their visit for a more comprehensive experience.\\n</think>\\n\\nThe best places to see Orcas (also known as \"Orcas\" or \"Humphead Whales\") in the U.S. are located along the west coast of North America. Orcas are one of the most distinctive and easily recognizable animals in the ocean, and their populations in the U.S. have been studied extensively due to their large size and migration patterns. Here\\'s a list of top places where you can see Orcas:\\n\\n### 1. **Haida Gorda Peninsula, Alaska**\\n   - This remote area on the west coast of Alaska is one of the best places to spot Orcas. It’s known for having some of the highest concentrations of these whales in North America.\\n   - The area has several boat tours that are specifically designed to maximize sightings, and local regulations often allow hunters to takeorative photos or videos (but never feed them).\\n   - **Why Visit:** You can see up to 10 Orcas per trip.\\n\\n### 2. **Orcas in Washington**\\n   - Orcas live off the coast of Washington State, including the regions around Puget Sound and Vancouver Island.\\n   - Boating tours are a great way to spot them, as they tend to be abundant in this area year-round (except for winter).\\n   - **Tip:** Visit during the summer months when weather is warmer.\\n\\n### 3. **Northern Orcas**\\n   - Northern Orcas live along the western coast of Canada and Alaska. They migrate northward each year to feed on sealmeat.\\n   - If you\\'re visiting during the fall or winter, you may also see them in the Chilcotin Peninsula of British Columbia.\\n\\n### 4. **Idaho-Nevada (Graham Bank)**\\n   - A small group of Orcas called the Graham Bank population has been studied for decades due to their unique migration patterns.\\n   - While sightings are rare, it’s a great place to see these elusive creatures if you’re willing to wait.\\n\\n### 5. **Coastal Areas of Oregon andCalifornia**\\n   - Occasional Orcas have been sighted in coastal areas of Oregon and California, though these populations aren’t as active or abundant as those along the Alaskan coast.\\n\\n### Tips for Visiting:\\n- **Timing:** Visit during peak seasons (spring and fall) to maximize your chances of seeing Orcas.\\n- **Reservations:** Make advance reservations for boat tours to ensure a better chance of spotting them.\\n- **Ethics:** While respecting their privacy, try not to feed or approach them too closely—Orcas are wild animals who enjoy their independence.\\n\\nIf you’re planning a trip to the U.S. to see Orcas, focus on areas like Haida Gorda Peninsula in Alaska for the best encounters!', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:7b', 'created_at': '2025-02-24T05:46:09.51689Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23909153833, 'load_duration': 571233333, 'prompt_eval_count': 49, 'prompt_eval_duration': 5277000000, 'eval_count': 806, 'eval_duration': 17820000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-19e42bd1-2e82-4408-ab8f-609572658599-0', usage_metadata={'input_tokens': 49, 'output_tokens': 806, 'total_tokens': 855})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:47:10.601532Z",
     "start_time": "2025-02-24T05:47:10.596216Z"
    }
   },
   "cell_type": "code",
   "source": "result.response_metadata",
   "id": "f3c9c0141b30ec79",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'deepseek-r1:7b',\n",
       " 'created_at': '2025-02-24T05:46:09.51689Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 23909153833,\n",
       " 'load_duration': 571233333,\n",
       " 'prompt_eval_count': 49,\n",
       " 'prompt_eval_duration': 5277000000,\n",
       " 'eval_count': 806,\n",
       " 'eval_duration': 17820000000,\n",
       " 'message': Message(role='assistant', content='', images=None, tool_calls=None)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "When a model has to interact with external systems you have to use **tools**.",
   "id": "55dba397ef662b47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:49:35.261510Z",
     "start_time": "2025-02-24T05:49:34.883893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multipled by 3\", name=\"Adam\")])"
   ],
   "id": "71771ebb5c5a4e30",
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "registry.ollama.ai/library/deepseek-r1:7b does not support tools (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResponseError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 6\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a \u001B[38;5;241m*\u001B[39m b\n\u001B[1;32m      4\u001B[0m llm_with_tools \u001B[38;5;241m=\u001B[39m llm\u001B[38;5;241m.\u001B[39mbind_tools([multiply])\n\u001B[0;32m----> 6\u001B[0m tool_call \u001B[38;5;241m=\u001B[39m \u001B[43mllm_with_tools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat is 2 multipled by 3\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAdam\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/runnables/base.py:5360\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   5354\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   5355\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5356\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   5357\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   5358\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   5359\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m-> 5360\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5361\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5362\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5363\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5364\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    283\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:860\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    854\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    858\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    859\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:690\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 690\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    696\u001B[0m         )\n\u001B[1;32m    697\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:925\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 925\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    929\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_ollama/chat_models.py:701\u001B[0m, in \u001B[0;36mChatOllama._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_generate\u001B[39m(\n\u001B[1;32m    695\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    696\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    700\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatResult:\n\u001B[0;32m--> 701\u001B[0m     final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_chat_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    704\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m final_chunk\u001B[38;5;241m.\u001B[39mgeneration_info\n\u001B[1;32m    705\u001B[0m     chat_generation \u001B[38;5;241m=\u001B[39m ChatGeneration(\n\u001B[1;32m    706\u001B[0m         message\u001B[38;5;241m=\u001B[39mAIMessage(\n\u001B[1;32m    707\u001B[0m             content\u001B[38;5;241m=\u001B[39mfinal_chunk\u001B[38;5;241m.\u001B[39mtext,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    711\u001B[0m         generation_info\u001B[38;5;241m=\u001B[39mgeneration_info,\n\u001B[1;32m    712\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_ollama/chat_models.py:602\u001B[0m, in \u001B[0;36mChatOllama._chat_stream_with_aggregation\u001B[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_chat_stream_with_aggregation\u001B[39m(\n\u001B[1;32m    594\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    595\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    599\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    600\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatGenerationChunk:\n\u001B[1;32m    601\u001B[0m     final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 602\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mChatGenerationChunk\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    605\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAIMessageChunk\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    619\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_ollama/chat_models.py:589\u001B[0m, in \u001B[0;36mChatOllama._create_chat_stream\u001B[0;34m(self, messages, stop, **kwargs)\u001B[0m\n\u001B[1;32m    586\u001B[0m chat_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_chat_params(messages, stop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    588\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chat_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 589\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mchat(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mchat_params)\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    591\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mchat(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mchat_params)\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/ollama/_client.py:168\u001B[0m, in \u001B[0;36mClient._request.<locals>.inner\u001B[0;34m()\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    167\u001B[0m   e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m--> 168\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mtext, e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mstatus_code) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_lines():\n\u001B[1;32m    171\u001B[0m   part \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(line)\n",
      "\u001B[0;31mResponseError\u001B[0m: registry.ollama.ai/library/deepseek-r1:7b does not support tools (status code: 400)"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:50:50.555963Z",
     "start_time": "2025-02-24T05:50:50.537336Z"
    }
   },
   "cell_type": "code",
   "source": "tool_call.tool_calls",
   "id": "59b5566dd6c9c760",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tool_call' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtool_call\u001B[49m\u001B[38;5;241m.\u001B[39mtool_calls\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tool_call' is not defined"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:53:37.728761Z",
     "start_time": "2025-02-24T05:53:31.747614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPEN_AI_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ],
   "id": "eb915784b28bb2d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:53:41.124293Z",
     "start_time": "2025-02-24T05:53:41.120017Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "460cd122ad501ca8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The best place to see orcas, also known as killer whales, in the United States is the Pacific Northwest, particularly the waters around the San Juan Islands in Washington State. Known for their breathtaking natural beauty, these islands are a hotspot for orca watching.\\n\\nOrcas are frequently sighted in the waters around these islands, especially during the summer months when salmon, their primary food source, are abundant. The resident orca pods, known as the Southern Resident Killer Whales, are often seen here. Tours depart from places like Friday Harbor on San Juan Island, as well as from Anacortes and Seattle on the mainland.\\n\\nApart from the San Juan Islands, the Strait of Juan de Fuca and Puget Sound also provide excellent opportunities for orca watching. These areas are rich in marine life, making them ideal habitats for orcas.\\n\\nRemember that orca watching tours can have varying impacts on the whales, so it’s beneficial to choose operators that follow guidelines for responsible whale watching to minimize the disturbance to these magnificent animals.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 67, 'total_tokens': 274, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-a82b9296-522c-4208-aee5-1006b9835676-0', usage_metadata={'input_tokens': 67, 'output_tokens': 207, 'total_tokens': 274, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:55:44.512595Z",
     "start_time": "2025-02-24T05:55:43.777011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Adam\")])"
   ],
   "id": "553762e53e7049d1",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:55:46.027602Z",
     "start_time": "2025-02-24T05:55:46.023327Z"
    }
   },
   "cell_type": "code",
   "source": "tool_call.tool_calls",
   "id": "9b91d7bb2c960db1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_ubsmaPiqSuzsDxte87VJrnya',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T05:59:18.724090Z",
     "start_time": "2025-02-24T05:59:18.721482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ],
   "id": "919ff4aefebd7fe5",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reducers\n",
    "**Reducers** are key to understanding how updates from nodes are applied to the `State`. Each key in the `State` has its own independent reducer function. If no reducer function is explicitly specified then it is assumed that all updates to that key should override it."
   ],
   "id": "c964e53d65401596"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
