{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-22T23:42:28.892243Z",
     "start_time": "2025-02-22T23:42:27.511321Z"
    }
   },
   "source": [
    "!pip install langchain-ollama\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun, AsyncCallbackManagerForLLMRun\n",
    "from langchain_core.outputs import ChatResult\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPEN_AI_KEY')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\r\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-ollama) (0.3.37)\r\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama)\r\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.10)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.2)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\r\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\r\n",
      "Requirement already satisfied: anyio in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.8.0)\r\n",
      "Requirement already satisfied: certifi in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.32.3)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.3.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/adamcobb/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\r\n",
      "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\r\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\r\n",
      "Installing collected packages: ollama, langchain-ollama\r\n",
      "Successfully installed langchain-ollama-0.2.3 ollama-0.4.7\r\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "ollama_chat = ChatOllama(model=\"deepseek-r1:14b\", temperature=0)"
   ],
   "id": "53760c37cd9ef56d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T23:44:49.573423Z",
     "start_time": "2025-02-22T23:44:46.759368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Say Hello\", name=\"Adam\")\n",
    "\n",
    "# Create a message list\n",
    "messages = [msg]\n",
    "\n",
    "#Invoke a model with a list of messages\n",
    "gpt4o_chat.invoke(messages)\n",
    "ollama_chat.invoke(messages)"
   ],
   "id": "34e803c6ec5f4a3d",
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 115)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/requests/models.py:963\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 963\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcomplexjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mUnicodeDecodeError\u001B[39;00m:\n\u001B[1;32m    965\u001B[0m     \u001B[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001B[39;00m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001B[39;00m\n\u001B[1;32m    967\u001B[0m     \u001B[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001B[39;00m\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;66;03m# used.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/json/decoder.py:348\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n\u001B[0;32m--> 348\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtra data\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, end)\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Extra data: line 2 column 1 (char 115)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#Invoke a model with a list of messages\u001B[39;00m\n\u001B[1;32m     10\u001B[0m gpt4o_chat\u001B[38;5;241m.\u001B[39minvoke(messages)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mollama_chat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    283\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:860\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    854\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    858\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    859\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:690\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 690\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    696\u001B[0m         )\n\u001B[1;32m    697\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:929\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    925\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[1;32m    926\u001B[0m             messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    927\u001B[0m         )\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 929\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[38;5;66;03m# Add response metadata to each generation\u001B[39;00m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, generation \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(result\u001B[38;5;241m.\u001B[39mgenerations):\n",
      "Cell \u001B[0;32mIn[23], line 38\u001B[0m, in \u001B[0;36mChatOllama._generate\u001B[0;34m(self, messages, stop, **kwargs)\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     37\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mget_role(message)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessage\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m messages])\n\u001B[0;32m---> 38\u001B[0m output_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: output_text}\n",
      "Cell \u001B[0;32mIn[23], line 20\u001B[0m, in \u001B[0;36mChatOllama._call\u001B[0;34m(self, prompt, stop)\u001B[0m\n\u001B[1;32m     18\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/api/generate\u001B[39m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m=\u001B[39mpayload)\n\u001B[1;32m     19\u001B[0m response\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[0;32m---> 20\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mstrip()\n",
      "File \u001B[0;32m~/.local/share/mise/installs/python/3.13.2/lib/python3.13/site-packages/requests/models.py:971\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    969\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    970\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 971\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m RequestsJSONDecodeError(e\u001B[38;5;241m.\u001B[39mmsg, e\u001B[38;5;241m.\u001B[39mdoc, e\u001B[38;5;241m.\u001B[39mpos)\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m complexjson\u001B[38;5;241m.\u001B[39mloads(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Extra data: line 2 column 1 (char 115)"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
